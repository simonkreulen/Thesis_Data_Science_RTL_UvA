{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd7c8f2a-adab-40d5-99f4-2117949d0d38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### In this notebook, all the evaluation on model performances on recall and similarity scores is shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13accdc3-4c22-41b2-9f88-5e9f8f5d9e4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df141cf4-7691-434b-b9ed-a5d08016ec94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "##### Loading in results, and changing some column names to align the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21be4317-ee37-4af0-aa1f-4b22d2ff14cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROGRAM_ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>Generated_Tags</th>\n",
       "      <th>Actual_Tags</th>\n",
       "      <th>Matching_Tags_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0033045</td>\n",
       "      <td>The Shop Around the Corner</td>\n",
       "      <td>[comedy, romantic, entertaining, flashback]</td>\n",
       "      <td>[romantic]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt1937113</td>\n",
       "      <td>Call of Duty: Modern Warfare 3</td>\n",
       "      <td>[violence, flashback, murder, action, suspense...</td>\n",
       "      <td>[good versus evil]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0102007</td>\n",
       "      <td>The Haunted</td>\n",
       "      <td>[paranormal, horror]</td>\n",
       "      <td>[haunting, horror, paranormal]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt2005374</td>\n",
       "      <td>The Frozen Ground</td>\n",
       "      <td>[murder, violence]</td>\n",
       "      <td>[dramatic, murder]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt1411238</td>\n",
       "      <td>No Strings Attached</td>\n",
       "      <td>[romantic, pornographic]</td>\n",
       "      <td>[adult comedy, boring, cute, entertaining, fla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PROGRAM_ID  ... Matching_Tags_Count\n",
       "0  tt0033045  ...                   1\n",
       "1  tt1937113  ...                   0\n",
       "2  tt0102007  ...                   2\n",
       "3  tt2005374  ...                   1\n",
       "4  tt1411238  ...                   1\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### BASELINE\n",
    "\n",
    "results_baseline = spark.read.table(\"dev_data_science.mpst_dataset.results_baseline\")\n",
    "results_baseline = results_baseline.toPandas()\n",
    "results_baseline.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c616f505-a7ec-4d20-8438-9324a752bb9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>title</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>tags</th>\n",
       "      <th>split</th>\n",
       "      <th>synopsis_source</th>\n",
       "      <th>award_label</th>\n",
       "      <th>tag_count</th>\n",
       "      <th>Generated_Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0033045</td>\n",
       "      <td>The Shop Around the Corner</td>\n",
       "      <td>Matuschek's, a gift store in Budapest, is the ...</td>\n",
       "      <td>[romantic]</td>\n",
       "      <td>test</td>\n",
       "      <td>imdb</td>\n",
       "      <td>No award</td>\n",
       "      <td>1</td>\n",
       "      <td>[romantic, comedy, dramatic, mystery, sentimen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt1937113</td>\n",
       "      <td>Call of Duty: Modern Warfare 3</td>\n",
       "      <td>Hours after the end of the previous game and t...</td>\n",
       "      <td>[good versus evil]</td>\n",
       "      <td>test</td>\n",
       "      <td>imdb</td>\n",
       "      <td>No award</td>\n",
       "      <td>1</td>\n",
       "      <td>[action, suspenseful, dramatic, revenge, viole...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0102007</td>\n",
       "      <td>The Haunted</td>\n",
       "      <td>This creepy and scary story centers around The...</td>\n",
       "      <td>[paranormal, horror, haunting]</td>\n",
       "      <td>test</td>\n",
       "      <td>imdb</td>\n",
       "      <td>No award</td>\n",
       "      <td>3</td>\n",
       "      <td>[horror, paranormal, dark, haunting, mystery, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt2005374</td>\n",
       "      <td>The Frozen Ground</td>\n",
       "      <td>The film opens in an Anchorage motel room in 1...</td>\n",
       "      <td>[dramatic, murder]</td>\n",
       "      <td>test</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>No award</td>\n",
       "      <td>2</td>\n",
       "      <td>[suspenseful, dark, murder, psychological, mys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt1411238</td>\n",
       "      <td>No Strings Attached</td>\n",
       "      <td>15 years agoWe see two young kids, named Emma ...</td>\n",
       "      <td>[boring, adult comedy, cute, flashback, romant...</td>\n",
       "      <td>test</td>\n",
       "      <td>imdb</td>\n",
       "      <td>No award</td>\n",
       "      <td>6</td>\n",
       "      <td>[comedy, romantic, adult comedy, feel-good, dr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     imdb_id  ...                                     Generated_Tags\n",
       "0  tt0033045  ...  [romantic, comedy, dramatic, mystery, sentimen...\n",
       "1  tt1937113  ...  [action, suspenseful, dramatic, revenge, viole...\n",
       "2  tt0102007  ...  [horror, paranormal, dark, haunting, mystery, ...\n",
       "3  tt2005374  ...  [suspenseful, dark, murder, psychological, mys...\n",
       "4  tt1411238  ...  [comedy, romantic, adult comedy, feel-good, dr...\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_pretrained = spark.read.table(\"dev_data_science.mpst_dataset.results_pretrained2\")\n",
    "results_pretrained = results_pretrained.toPandas()\n",
    "results_pretrained.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aac66866-cc56-470b-8c6a-7809e946be30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results_pretrained = results_pretrained.rename(columns={\"tags\": \"Actual_Tags\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6fb8a0e-50ff-4435-a803-7106b81efdb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results_pretrained = results_pretrained.rename(columns={'tag_count': 'Matching_Tags_Count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c350c65a-4fdb-4479-afdd-25018b7da72f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>title</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>tags</th>\n",
       "      <th>split</th>\n",
       "      <th>synopsis_source</th>\n",
       "      <th>award_label</th>\n",
       "      <th>tag_count</th>\n",
       "      <th>Generated_Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0033045</td>\n",
       "      <td>The Shop Around the Corner</td>\n",
       "      <td>Matuschek's, a gift store in Budapest, is the ...</td>\n",
       "      <td>[romantic]</td>\n",
       "      <td>test</td>\n",
       "      <td>imdb</td>\n",
       "      <td>No award</td>\n",
       "      <td>1</td>\n",
       "      <td>[romantic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt1937113</td>\n",
       "      <td>Call of Duty: Modern Warfare 3</td>\n",
       "      <td>Hours after the end of the previous game and t...</td>\n",
       "      <td>[good versus evil]</td>\n",
       "      <td>test</td>\n",
       "      <td>imdb</td>\n",
       "      <td>No award</td>\n",
       "      <td>1</td>\n",
       "      <td>[action, violence, revenge, suspenseful, dark]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0102007</td>\n",
       "      <td>The Haunted</td>\n",
       "      <td>This creepy and scary story centers around The...</td>\n",
       "      <td>[paranormal, horror, haunting]</td>\n",
       "      <td>test</td>\n",
       "      <td>imdb</td>\n",
       "      <td>No award</td>\n",
       "      <td>3</td>\n",
       "      <td>[horror]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt2005374</td>\n",
       "      <td>The Frozen Ground</td>\n",
       "      <td>The film opens in an Anchorage motel room in 1...</td>\n",
       "      <td>[dramatic, murder]</td>\n",
       "      <td>test</td>\n",
       "      <td>wikipedia</td>\n",
       "      <td>No award</td>\n",
       "      <td>2</td>\n",
       "      <td>[murder, suspenseful, psychological, dark, vio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt1411238</td>\n",
       "      <td>No Strings Attached</td>\n",
       "      <td>15 years agoWe see two young kids, named Emma ...</td>\n",
       "      <td>[boring, adult comedy, cute, flashback, romant...</td>\n",
       "      <td>test</td>\n",
       "      <td>imdb</td>\n",
       "      <td>No award</td>\n",
       "      <td>6</td>\n",
       "      <td>[comedy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     imdb_id  ...                                     Generated_Tags\n",
       "0  tt0033045  ...                                         [romantic]\n",
       "1  tt1937113  ...     [action, violence, revenge, suspenseful, dark]\n",
       "2  tt0102007  ...                                           [horror]\n",
       "3  tt2005374  ...  [murder, suspenseful, psychological, dark, vio...\n",
       "4  tt1411238  ...                                           [comedy]\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### FINETUNED\n",
    "\n",
    "results_finetuned = spark.read.table(\"dev_data_science.mpst_dataset.results_finetuned\")\n",
    "results_finetuned = results_finetuned.toPandas()\n",
    "results_finetuned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d52646c-b92e-409d-af57-f59a95c48dc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results_finetuned = results_finetuned.rename(columns={'tag_count': 'Matching_Tags_Count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f803a56-e079-48bf-a2f9-63e85c819b24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results_finetuned = results_finetuned.rename(columns={'tags': 'Actual_Tags'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5821c6e-b9b3-4144-9604-2089feb3221b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c6674fd83f43ada333a49b84c992a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b1c7f827934df28387e2942212d04e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e89f68aa644c69805e45a578778f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fec0e24580742249f6334c9af8f68b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5f7d40d32248629626854e74539b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the BERT model and tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Function to get embeddings using BERT\n",
    "def get_bert_embeddings(text):\n",
    "    # Tokenize and process input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Extract the `[CLS]` token embedding for sentence-level representation\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :]  # [batch_size, seq_length, hidden_size] -> [batch_size, hidden_size]\n",
    "    return cls_embedding\n",
    "\n",
    "# Function to calculate cosine similarity\n",
    "def calculate_similarity_bert(tags1, tags2):\n",
    "    # Convert tag lists to strings\n",
    "    text1 = \" \".join(tags1)\n",
    "    text2 = \" \".join(tags2)\n",
    "    \n",
    "    # Get BERT embeddings for each text\n",
    "    emb1 = get_bert_embeddings(text1)\n",
    "    emb2 = get_bert_embeddings(text2)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarity = cosine_similarity(emb1.numpy(), emb2.numpy())\n",
    "    return similarity[0][0]\n",
    "\n",
    "# Function to calculate matching tags count\n",
    "def compute_matching_tags(row):\n",
    "    return len(set(row[\"Generated_Tags\"]).intersection(set(row[\"Actual_Tags\"])))\n",
    "\n",
    "# Main function to process any dataframe\n",
    "def evaluate_tags(dataframe):\n",
    "    # Calculate similarity score\n",
    "    dataframe[\"Similarity_Score\"] = dataframe.apply(\n",
    "        lambda row: calculate_similarity_bert(row[\"Generated_Tags\"], row[\"Actual_Tags\"]),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Calculate matching tags count\n",
    "    dataframe[\"Matching_Tags_Count\"] = dataframe.apply(compute_matching_tags, axis=1)\n",
    "    \n",
    "    # Calculate recall\n",
    "    dataframe[\"Recall\"] = dataframe[\"Matching_Tags_Count\"] / dataframe[\"Actual_Tags\"].apply(len)\n",
    "    \n",
    "    # Compute average recall\n",
    "    average_recall = dataframe[\"Recall\"].mean()\n",
    "\n",
    "    average_sim_score = dataframe[\"Similarity_Score\"].mean()\n",
    "\n",
    "    \n",
    "    return dataframe, average_recall, average_sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b34cc83-9748-4e8c-809a-f0b0516cef2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall: 0.422538\nAverage Sim Score: 0.863028\n"
     ]
    }
   ],
   "source": [
    "#### USE THE FUNCTION ON EACH RESULTS DATAFRAME\n",
    "eval_df, avg_recall, average_sim_score = evaluate_tags(results_finetuned)\n",
    "\n",
    "print(f\"Average Recall: {avg_recall:.6f}\")\n",
    "print(f\"Average Sim Score: {average_sim_score:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "FINAL_EVALUATION",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}